{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175b64a8",
   "metadata": {},
   "source": [
    "# HTGP模型接入\n",
    "\n",
    "## 1. 导入checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69096607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型参数加载成功！\n",
      "模型总参数量: 630440\n",
      "HTGPConfig(num_atom_types=100, hidden_dim=96, num_layers=2, cutoff=6.0, num_rbf=10, atom_types_map=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100], use_L0=True, use_L1=True, use_L2=True, use_gating=True, avg_neighborhood=61.481112820672955, use_long_range=False, use_charge=False, use_vdw=False, use_dipole=False, FINETUNE_MODE=True, PRETRAINED_CKPT='Checkpoints_Old/model_epoch_50.pt', steps_per_epoch=None, long_range_scale=1, active_paths={(0, 0, 0, 'prod'): True, (0, 1, 1, 'prod'): True, (0, 2, 2, 'prod'): True, (1, 0, 1, 'prod'): True, (1, 1, 0, 'dot'): True, (1, 1, 1, 'cross'): True, (1, 1, 2, 'outer'): True, (2, 0, 2, 'prod'): True, (2, 1, 1, 'mat_vec'): True, (1, 2, 1, 'vec_mat'): True, (2, 2, 0, 'double_dot'): True, (2, 2, 2, 'mat_mul_sym'): True})\n",
      "模型参数数据类型: {torch.float32}\n"
     ]
    }
   ],
   "source": [
    "from lmy.src.models import HTGPModel\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"./lmy/\")\n",
    "HTGP_PATH = \"../lmy_checkpoints/Checkpoints_break_2/model_epoch_47.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# dtypes = torch.float32 \n",
    "\n",
    "def load_HTGP_model(path: str, device: torch.device) -> HTGPModel:\n",
    "    checkpoint = torch.load(path, map_location=device, weights_only=False)\n",
    "    config = checkpoint['model_config']\n",
    "    model = HTGPModel(config)\n",
    "\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[7:]] = v \n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    try:\n",
    "        model.load_state_dict(new_state_dict, strict=False)\n",
    "        print(\"✅ 模型参数加载成功！\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"❌ 加载依然失败，请检查 Config 是否与训练一致。\\n详细错误: {e}\")\n",
    "\n",
    "    # 打印模型信息\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型总参数量: {total_params}\")\n",
    "    print(model.cfg)\n",
    "    dtypes = {p.dtype for p in model.parameters()}\n",
    "    print(f\"模型参数数据类型: {dtypes}\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "lmy_model = load_HTGP_model(HTGP_PATH, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610036d",
   "metadata": {},
   "source": [
    "## 2. 架构内数据流模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5875ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos shape:      torch.Size([2, 4, 3])\n",
      "Species shape:  torch.Size([2, 4, 60])\n",
      "Cell shape:     torch.Size([2, 3, 3])\n",
      "Node Mask shape: torch.Size([2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# 1. 设置基础参数\n",
    "B, N, C = 2, 4, 60  # Batch Size, Max Atoms, Element Types\n",
    "pos = torch.rand((B, N, 3), device=device) * 1.0  # 随机生成位置，范围在 [0, 5)\n",
    "species_indices = torch.randint(1, C, (B, N), device=device)\n",
    "species = torch.nn.functional.one_hot(species_indices, num_classes=C).float()\n",
    "cell = torch.eye(3, device=device).unsqueeze(0).repeat(B, 1, 1) * 10.0  # 简单的立方体晶胞\n",
    "node_mask = torch.tensor([\n",
    "    [[1.0], [1.0], [1.0], [1.0]], \n",
    "    [[1.0], [1.0], [1.0], [0.0]]\n",
    "], device=device)\n",
    "# 打印结果检查\n",
    "print(f\"Pos shape:      {pos.shape}\")         # [2, 4, 3]\n",
    "print(f\"Species shape:  {species.shape}\")     # [2, 4, 5]\n",
    "print(f\"Cell shape:     {cell.shape}\")        # [2, 3, 3]\n",
    "print(f\"Node Mask shape: {node_mask.shape}\")      # [2, 4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9532ff",
   "metadata": {},
   "source": [
    "## 3. 数据转换成 HTGP 输入形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f18559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "from ase.neighborlist import neighbor_list\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "\n",
    "def dense_to_atoms_list(pos, species, cell, node_mask) -> list[Atoms]:\n",
    "    \"\"\"\n",
    "    将 Dense Batch 转换为 ASE Atoms 列表\n",
    "    \n",
    "    参数:\n",
    "    pos: [B, N, 3] - 坐标\n",
    "    species: [B, N, C] - 原子序数\n",
    "    cell: [B, 3, 3] - 晶胞\n",
    "    node_mask: [B, N, 1] - 掩码\n",
    "    \"\"\"\n",
    "    B, N, _ = pos.shape\n",
    "    atoms_list = []\n",
    "    \n",
    "    # 将 Tensor 转到 CPU 方便 ASE 处理\n",
    "    pos_cpu = pos.detach().cpu().numpy()\n",
    "    cell_cpu = cell.detach().cpu().numpy()\n",
    "    species = torch.argmax(species, dim=-1)\n",
    "    z_cpu = species.detach().cpu().numpy()\n",
    "    mask_cpu = node_mask.detach().cpu().numpy().squeeze(-1) > 0\n",
    "\n",
    "    for i in range(B):\n",
    "        # 提取有效原子\n",
    "        m = mask_cpu[i]\n",
    "        curr_pos = pos_cpu[i][m]\n",
    "        curr_z = z_cpu[i][m]\n",
    "        curr_cell = cell_cpu[i]\n",
    "\n",
    "        # 创建 ASE Atoms 对象\n",
    "        temp_atoms = Atoms(numbers=curr_z, positions=curr_pos, cell=curr_cell, pbc=True)\n",
    "        atoms_list.append(temp_atoms)\n",
    "\n",
    "    return atoms_list\n",
    "\n",
    "def dense_to_pyg_batch(pos, species, cell, node_mask, cutoff, device):\n",
    "    \"\"\"\n",
    "    参考 _atoms_to_pyg_data 的逻辑，将 Dense Batch 转换为 PyG Batch\n",
    "    \n",
    "    参数:\n",
    "    pos: [B, N, 3] - 坐标\n",
    "    species: [B, N, C] - 原子序数\n",
    "    cell: [B, 3, 3] - 晶胞\n",
    "    node_mask: [B, N, 1] - 掩码\n",
    "    \"\"\"\n",
    "    B, N, _ = pos.shape\n",
    "    data_list = []\n",
    "    \n",
    "    # 将 Tensor 转到 CPU 方便 ASE 处理邻居表 (ASE 不支持 GPU 邻居表计算)\n",
    "    pos_cpu = pos.detach().cpu().numpy()\n",
    "    cell_cpu = cell.detach().cpu().numpy()\n",
    "    species = torch.argmax(species, dim=-1)\n",
    "    z_cpu = species.detach().cpu().numpy()\n",
    "    mask_cpu = node_mask.detach().cpu().numpy().squeeze(-1) > 0\n",
    "\n",
    "    for i in range(B):\n",
    "        # 1. 提取有效原子\n",
    "        m = mask_cpu[i]\n",
    "        curr_pos = pos_cpu[i][m]\n",
    "        curr_z = z_cpu[i][m]\n",
    "        curr_cell = cell_cpu[i]\n",
    "\n",
    "        # 2. 创建临时 ASE Atoms 对象 (为了复用 neighbor_list 逻辑)\n",
    "        # 注意: 这里假设是周期性的，如果是分子则 pbc=[False, False, False]\n",
    "        temp_atoms = Atoms(numbers=curr_z, positions=curr_pos, cell=curr_cell, pbc=True)\n",
    "        num_atoms = len(temp_atoms)\n",
    "        batch = torch.zeros(num_atoms, dtype=torch.long).to(device)\n",
    "\n",
    "        # 3. 计算邻居表 - 严格复刻你提供的 'ijdS' 逻辑\n",
    "        i_idx, j_idx, _, S_integers = neighbor_list('ijdS', temp_atoms, cutoff)\n",
    "\n",
    "        # 4. 组装为 PyG Data 对象\n",
    "        # 将结果转回指定的 device\n",
    "        data = Data(\n",
    "            z=torch.from_numpy(curr_z).to(torch.long).to(device),\n",
    "            pos=pos[i][mask_cpu[i]], # 保持梯度追踪\n",
    "            cell=cell[i].unsqueeze(0), # 形状 [1, 3, 3]\n",
    "            edge_index=torch.tensor(np.vstack((i_idx, j_idx)), dtype=torch.long).to(device),\n",
    "            shifts_int=torch.from_numpy(S_integers).to(torch.float32).to(device),\n",
    "            batch=batch\n",
    "        )\n",
    "        data.num_nodes = len(curr_z)\n",
    "        data.num_graphs = 1\n",
    "        data_list.append(data)\n",
    "\n",
    "    # 5. 合并为 PyG Batch\n",
    "    # Batch.from_data_list 会自动处理 batch 属性和索引偏移\n",
    "    pyg_batch = Batch.from_data_list(data_list)\n",
    "    \n",
    "    return pyg_batch.to(device), data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859092d",
   "metadata": {},
   "source": [
    "## 4. 模型 forward 计算各种性质"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec31d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Energy: 775.1927490234375 eV\n",
      "positions:, [[0.83899093 0.4275907  0.77417934]\n",
      " [0.12738533 0.98398918 0.37296629]\n",
      " [0.02028096 0.18894708 0.65469432]\n",
      " [0.33082721 0.44240227 0.49594921]], \n",
      "Predicted Forces:\n",
      "[[ 241.72588   203.49521    21.66552 ]\n",
      " [-215.67813   444.99152     3.932743]\n",
      " [-643.8226    -96.32204    60.000954]\n",
      " [ 617.7749   -552.16473   -85.59921 ]]\n",
      "Predicted Stress:\n",
      "[-0.36665094 -0.26240054 -0.01506919  0.01339851  0.00842356 -0.04279144]\n",
      "Predicted Energy: 289.4280700683594 eV\n",
      "positions:, [[0.59786505 0.17394595 0.52950513]\n",
      " [0.91123998 0.02964883 0.98903912]\n",
      " [0.85767126 0.32990023 0.30413806]], \n",
      "Predicted Forces:\n",
      "[[-456.71783  -251.79047   346.9703  ]\n",
      " [   9.063694   57.66429  -122.765656]\n",
      " [ 447.65414   194.12616  -224.20465 ]]\n",
      "Predicted Stress:\n",
      "[-0.11914366 -0.02195402  0.00588663  0.01725095  0.09672148 -0.06850573]\n"
     ]
    }
   ],
   "source": [
    "from lmy.src.utils import HTGP_Calculator\n",
    "\n",
    "# convert batch\n",
    "pyg_data, data_list = dense_to_pyg_batch(pos, species, cell, node_mask, cutoff=6.0, device=device)\n",
    "atoms_list = dense_to_atoms_list(pos, species, cell, node_mask)\n",
    "\n",
    "# HTGP calculator\n",
    "lmy_model.eval()\n",
    "lmy_calculator = HTGP_Calculator(lmy_model, cutoff=6.0, device=device)\n",
    "\n",
    "for atoms in atoms_list:\n",
    "    atoms.calc = lmy_calculator\n",
    "    energy = lmy_calculator.get_potential_energy(atoms)\n",
    "    print(f\"Predicted Energy: {energy} eV\")\n",
    "    force = lmy_calculator.get_forces(atoms)\n",
    "    print(f\"positions:, {atoms.get_positions()}, \\nPredicted Forces:\\n{force}\")\n",
    "    stress = lmy_calculator.get_stress(atoms)\n",
    "    print(f\"Predicted Stress:\\n{stress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683312e7",
   "metadata": {},
   "source": [
    "## 5. 通过本地数据计算 energy_above_hull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c7732",
   "metadata": {},
   "source": [
    "### 5.1 导入本地数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2628377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcw/miniconda3/envs/mpgem/lib/python3.10/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for Ar. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n",
      "/home/mcw/miniconda3/envs/mpgem/lib/python3.10/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for He. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n",
      "/home/mcw/miniconda3/envs/mpgem/lib/python3.10/site-packages/pymatgen/core/composition.py:1366: UserWarning: No Pauling electronegativity for Ne. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  syms: list[str] = sorted(sym_amt, key=lambda x: [get_el_sp(x).X, x])\n"
     ]
    }
   ],
   "source": [
    "from monty.serialization import loadfn\n",
    "database_path =  \"../mp_stable_reference_84el.json.gz\"\n",
    "local_database = loadfn(database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ac6cd",
   "metadata": {},
   "source": [
    "### 5.2 本地计算器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65cb191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [本地] 正在计算能量校准参数...\n",
      ">>> 校准完成。共校准 2 种元素。\n",
      "Structure: {'Li': 2, 'O': 1}\n",
      "Energy Above Hull: 0.8289 eV/atom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcw/miniconda3/envs/mpgem/lib/python3.10/site-packages/uncertainties/core.py:1024: UserWarning: Using UFloat objects with std_dev==0 may give unexpected results.\n",
      "  warn(\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core import Composition, Structure\n",
    "from pymatgen.analysis.phase_diagram import PhaseDiagram, PDEntry\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "class LocalHullCalculator:\n",
    "    def __init__(self, all_entries):\n",
    "        \"\"\"\n",
    "        全本地计算器。\n",
    "        \n",
    "        Args:\n",
    "            all_entries (list[PDEntry]): \n",
    "                你从本地文件加载进来的所有参考相。\n",
    "                (e.g. pd_entries = loadfn('my_local_mp_database.json'))\n",
    "        \"\"\"\n",
    "        self.all_entries = all_entries\n",
    "        self.model_offsets = {} \n",
    "        self.is_calibrated = False\n",
    "\n",
    "    def calibrate(self, validation_data):\n",
    "        \"\"\"\n",
    "        算出 MLP 和 MP 之间的系统误差。\n",
    "        \n",
    "        Args:\n",
    "            validation_data (list[dict]): 你的本地验证集数据\n",
    "            格式: [{\"composition\": \"Li2O\", \"e_mlp\": -14.2, \"e_mp\": -15.1}, ...]\n",
    "            注意: 能量必须是 Total Energy (eV)，不是 per atom。\n",
    "        \"\"\"\n",
    "        print(\">>> [本地] 正在计算能量校准参数...\")\n",
    "        \n",
    "        # 1. 提取元素列表\n",
    "        elements = set()\n",
    "        for d in validation_data:\n",
    "            comp = Composition(d[\"composition\"])\n",
    "            elements.update([str(e) for e in comp.elements])\n",
    "        \n",
    "        sorted_elems = sorted(list(elements))\n",
    "        el_map = {el: i for i, el in enumerate(sorted_elems)}\n",
    "        \n",
    "        # 2. 构建方程 Ax = b\n",
    "        # A = 原子数矩阵, x = offset, b = (E_mlp - E_mp)\n",
    "        A = []\n",
    "        b = []\n",
    "        \n",
    "        for d in validation_data:\n",
    "            comp = Composition(d[\"composition\"])\n",
    "            row = [0.0] * len(sorted_elems)\n",
    "            for el, amt in comp.items():\n",
    "                row[el_map[str(el)]] = amt\n",
    "            A.append(row)\n",
    "            b.append(d[\"e_mlp\"] - d[\"e_mp\"]) # 差值\n",
    "\n",
    "        # 3. 求解线性方程 (最小二乘法)\n",
    "        reg = LinearRegression(fit_intercept=False) # 必须无截距\n",
    "        reg.fit(A, b)\n",
    "        \n",
    "        # 4. 存入字典\n",
    "        self.model_offsets = dict(zip(sorted_elems, reg.coef_))\n",
    "        self.is_calibrated = True\n",
    "        \n",
    "        print(f\">>> 校准完成。共校准 {len(sorted_elems)} 种元素。\")\n",
    "        # print(self.model_offsets) # 调试用\n",
    "\n",
    "\n",
    "    def set_model_offsets(self, offsets_dict):\n",
    "        \"\"\"\n",
    "        手动设置模型偏差。\n",
    "        \n",
    "        Args:\n",
    "            offsets_dict (dict): {元素: eV/atom}\n",
    "        \"\"\"\n",
    "        self.model_offsets = offsets_dict\n",
    "        self.is_calibrated = True\n",
    "        print(f\">>> 手动设置模型偏差，共设置 {len(offsets_dict)} 种元素。\")\n",
    "\n",
    "\n",
    "    def get_ehull(self, composition_dict, total_energy):\n",
    "        \"\"\"\n",
    "        计算 Energy Above Hull (本地版)\n",
    "        \n",
    "        Args:\n",
    "            composition_dict: 字典，如 {\"Li\": 2, \"Fe\": 1, \"O\": 4}\n",
    "            total_energy: 你的模型预测的【结构总能量】(Total eV)，不要传 eV/atom\n",
    "        Returns:\n",
    "            float: Energy Above Hull (eV/atom)\n",
    "            None: 如果本地库缺数据算不出来\n",
    "        \"\"\"\n",
    "        # 1. 解析成分\n",
    "        comp = Composition(composition_dict)\n",
    "        chemsys = set(str(el) for el in comp.elements)\n",
    "\n",
    "        # 2. 能量校准\n",
    "        # 确保 self.model_offsets 是预先算好的 {元素: eV/atom}\n",
    "        correction = sum(comp[el] * self.model_offsets.get(str(el), 0) for el in comp.elements)\n",
    "        corrected_energy = total_energy - correction\n",
    "        \n",
    "        # 3. 从本地库筛选参考相\n",
    "        # 替代 mpr.get_entries_in_chemsys\n",
    "        # 遍历 self.all_entries，只保留元素集合属于当前 chemsys 子集的条目\n",
    "        relevant_entries = [\n",
    "            e for e in self.all_entries \n",
    "            if set(str(el) for el in e.composition.elements).issubset(chemsys)\n",
    "        ]\n",
    "\n",
    "        # --- 安全检查 (防崩溃) ---\n",
    "        if not relevant_entries:\n",
    "            print(f\"Error: 本地库中找不到体系 {chemsys} 的任何参考条目！\")\n",
    "            return None \n",
    "\n",
    "        # 4. 构建当前结构的 PDEntry\n",
    "        target_entry = PDEntry(comp, corrected_energy)\n",
    "\n",
    "        # 5. 构建相图并计算\n",
    "        try:\n",
    "            # 这里 Pymatgen 会自动用 relevant_entries 构建凸包\n",
    "            pd = PhaseDiagram(relevant_entries)\n",
    "            \n",
    "            # 计算 target_entry 距离凸包的垂直距离\n",
    "            e_above_hull = pd.get_e_above_hull(target_entry)\n",
    "            \n",
    "            return e_above_hull\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 常见错误：本地库虽然有数据，但缺端点元素(比如缺纯 Li 或纯 O)，无法画出封闭的相图\n",
    "            print(f\"相图构建失败 (可能缺失端点元素): {chemsys}, 错误信息: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# 初始化计算器\n",
    "HullCalculator = LocalHullCalculator(all_entries=local_database)\n",
    "\n",
    "# 用验证集做校准, 让 MLP 能量和 MP 能量“对齐”\n",
    "my_val_data = [\n",
    "    {\"composition\": \"Li\", \"e_mlp\": -1.8, \"e_mp\": -1.9},     # MLP比MP高0.1\n",
    "    {\"composition\": \"O2\", \"e_mlp\": -5.8, \"e_mp\": -9.88},    # MLP比MP高4.08 (缺气体校正)\n",
    "]\n",
    "HullCalculator.calibrate(my_val_data)\n",
    "\n",
    "# 开始批量计算 (完全离线)\n",
    "# 假设这是你 MLP 预测的新结构\n",
    "new_comp = {\"Li\": 2, \"O\": 1} \n",
    "new_energy = -12.1 # MLP 预测值\n",
    "\n",
    "ehull = HullCalculator.get_ehull(new_comp, new_energy)\n",
    "\n",
    "print(f\"Structure: {new_comp}\")\n",
    "print(f\"Energy Above Hull: {ehull:.4f} eV/atom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a678685",
   "metadata": {},
   "source": [
    "### 5.2 批量计算 offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ea3b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 正在进行元素分布分析与保底抽样...\n",
      ">>> 开始模型推理，生成校准数据 (有效样本数: 2086)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2086 [00:01<11:32,  3.01it/s]/home/mcw/miniconda3/envs/mpgem/lib/python3.10/site-packages/uncertainties/core.py:1024: UserWarning: Using UFloat objects with std_dev==0 may give unexpected results.\n",
      "  warn(\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n",
      "100%|██████████| 2086/2086 [03:31<00:00,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 校准完成！Offset 文件已保存至: ../htgp_to_mp_offsets.json\n",
      ">>> 共覆盖元素数量: 84\n",
      "succuessfully generated offsets !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pymatgen.core import Composition\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "def generate_offsets_for_htgp(all_entries, lmy_model, device, save_path, num_samples=1500):\n",
    "    \"\"\"\n",
    "    针对 HTGP 模型接口的大批量能量校准 (保底抽样版)\n",
    "    输入输出维持原样，确保 84 元素全覆盖。\n",
    "    \"\"\"\n",
    "    # 1. 初始化模型和转换器\n",
    "    adaptor = AseAtomsAdaptor()\n",
    "    calculator = HTGP_Calculator(lmy_model, cutoff=6.0, device=device)\n",
    "    lmy_model.eval()\n",
    "\n",
    "    # 2. 元素保底抽样逻辑 (核心改进)\n",
    "    print(\">>> 正在进行元素分布分析与保底抽样...\")\n",
    "    el_to_entries = defaultdict(list)\n",
    "    for entry in all_entries:\n",
    "        for el in entry.composition.elements:\n",
    "            el_to_entries[str(el)].append(entry)\n",
    "\n",
    "    selected_ids = set()\n",
    "    samples_per_el = 10 # 每种元素最少抓 10 个结构（如果有的话）\n",
    "\n",
    "    # 遍历所有存在的元素进行保底\n",
    "    for el, entries in el_to_entries.items():\n",
    "        draws = random.sample(entries, min(len(entries), samples_per_el))\n",
    "        for d in draws:\n",
    "            selected_ids.add(d.entry_id)\n",
    "\n",
    "    # 如果还没达到 num_samples，随机补齐\n",
    "    remaining_count = num_samples - len(selected_ids)\n",
    "    if remaining_count > 0:\n",
    "        all_ids = [e for e in all_entries if e.entry_id not in selected_ids]\n",
    "        additional_draws = random.sample(all_ids, min(len(all_ids), remaining_count))\n",
    "        for d in additional_draws:\n",
    "            selected_ids.add(d.entry_id)\n",
    "\n",
    "    # 提取最终抽样列表\n",
    "    sampled_entries = [e for e in all_entries if e.entry_id in selected_ids]\n",
    "    \n",
    "    # 3. 批量推理生成数据\n",
    "    val_data = []\n",
    "    print(f\">>> 开始模型推理，生成校准数据 (有效样本数: {len(sampled_entries)})...\")\n",
    "\n",
    "    for entry in tqdm(sampled_entries):\n",
    "        try:\n",
    "            # Pymatgen -> ASE\n",
    "            atoms = adaptor.get_atoms(entry.structure)\n",
    "            atoms.calc = calculator\n",
    "            # 获取 MLP 总能\n",
    "            e_mlp = calculator.get_potential_energy(atoms)\n",
    "            \n",
    "            val_data.append({\n",
    "                \"composition\": entry.composition,\n",
    "                \"e_mlp\": float(e_mlp),\n",
    "                \"e_mp\": float(entry.energy)\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # 4. 构建线性回归 Ax = b\n",
    "    elements = set()\n",
    "    for d in val_data:\n",
    "        elements.update([str(el) for el in d[\"composition\"].elements])\n",
    "    \n",
    "    sorted_elems = sorted(list(elements))\n",
    "    el_map = {el: i for i, el in enumerate(sorted_elems)}\n",
    "    \n",
    "    A, b = [], []\n",
    "    for d in val_data:\n",
    "        comp = d[\"composition\"]\n",
    "        row = [0.0] * len(sorted_elems)\n",
    "        for el, amt in comp.items():\n",
    "            row[el_map[str(el)]] = amt\n",
    "        A.append(row)\n",
    "        b.append(d[\"e_mlp\"] - d[\"e_mp\"])\n",
    "\n",
    "    # 求解 Offset\n",
    "    reg = LinearRegression(fit_intercept=False)\n",
    "    reg.fit(A, b)\n",
    "    offsets = dict(zip(sorted_elems, reg.coef_))\n",
    "    \n",
    "    # 保存结果\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(offsets, f, indent=4)\n",
    "    \n",
    "    print(f\">>> 校准完成！Offset 文件已保存至: {save_path}\")\n",
    "    print(f\">>> 共覆盖元素数量: {len(offsets)}\")\n",
    "    \n",
    "    # 检查是否覆盖了全部 84 元素（可选提示）\n",
    "    if len(offsets) < 84:\n",
    "        print(f\"提示：当前数据库及抽样仅覆盖了 {len(offsets)} 种元素，请确保这已包含你研究的所有体系。\")\n",
    "\n",
    "    return offsets\n",
    "\n",
    "OFFSET_PATH = \"../htgp_to_mp_offsets.json\"\n",
    "generate_offsets_for_htgp(local_database, lmy_model, device, OFFSET_PATH, num_samples=1500)\n",
    "with open(OFFSET_PATH, \"r\") as f:\n",
    "    model_offsets = json.load(f)\n",
    "print(\"succuessfully generated offsets !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd540b9",
   "metadata": {},
   "source": [
    "### 5.4 最终脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5eed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 手动设置模型偏差，共设置 84 种元素。\n",
      "Structure: {'Li': 2, 'O': 1}\n",
      "Energy Above Hull: 1.8633 eV/atom\n",
      "Energy Above Hull: 210.2184 eV/atom\n",
      "Energy Above Hull: 106.1852 eV/atom\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "HullCalculator.set_model_offsets(model_offsets)\n",
    "\n",
    "new_comp = {\"Li\": 2, \"O\": 1} \n",
    "new_energy = -12.1 # MLP 预测值\n",
    "ehull = HullCalculator.get_ehull(new_comp, new_energy)\n",
    "print(f\"Structure: {new_comp}\")\n",
    "print(f\"Energy Above Hull: {ehull:.4f} eV/atom\")\n",
    "\n",
    "for atoms in atoms_list:\n",
    "    pos = atoms.get_positions()\n",
    "    comp = dict(Counter(atoms.get_chemical_symbols())) # ex: {'Br': 1, 'P': 1, 'C': 1}\n",
    "\n",
    "    # MLP energy calculation\n",
    "    atoms.calc = lmy_calculator\n",
    "    energy = lmy_calculator.get_potential_energy(atoms)\n",
    "    force = lmy_calculator.get_forces(atoms)\n",
    "    stress = lmy_calculator.get_stress(atoms)\n",
    "    \n",
    "    # energy_hull calculation\n",
    "    ehull = HullCalculator.get_ehull(comp, energy)\n",
    "    print(f\"Energy Above Hull: {ehull:.4f} eV/atom\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpgem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
