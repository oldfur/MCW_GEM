import os
import glob
import random
import torch
import math
from torch.utils.data import IterableDataset

class ShardedPyGDataset(IterableDataset):
    def __init__(self, data_dir, prefix, shuffle=False):
        """
        :param data_dir: æ•°æ®ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„ (e.g., "processed_dataset")
        :param prefix: æ–‡ä»¶å‰ç¼€ (e.g., "train" æˆ– "test")
        :param shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ® (è®­ç»ƒé›† True, æµ‹è¯•é›† False)
        """
        super().__init__()
        self.data_dir = data_dir
        # 1. æ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶ (e.g., train_w0_part_0.pt, train_w1_part_5.pt ...)
        pattern = os.path.join(data_dir, f"{prefix}_*.pt")
        self.file_paths = sorted(glob.glob(pattern))
        self.shuffle = shuffle
        
        if len(self.file_paths) == 0:
            raise FileNotFoundError(f"âŒ æœªåœ¨ {data_dir} æ‰¾åˆ°ä»¥ {prefix} å¼€å¤´çš„æ–‡ä»¶ï¼")
        
        print(f"ğŸ“‚ [Dataset] Found {len(self.file_paths)} parts for '{prefix}'")

    def __iter__(self):
        """
        æ ¸å¿ƒæµå¼é€»è¾‘ï¼š
        æ¯æ¬¡è¿­ä»£æ—¶ï¼ŒWorker éƒ½ä¼šç‹¬ç«‹æ‰§è¡Œè¿™ä¸ªå‡½æ•°ã€‚
        åœ¨è¿™é‡Œè¿›è¡Œã€æ•°æ®ç±»å‹è¿˜åŸã€‘ï¼Œå°†å‹ç¼©å­˜å‚¨çš„æ•°æ®è½¬å›æ¨¡å‹éœ€è¦çš„æ ¼å¼ã€‚
        """
        worker_info = torch.utils.data.get_worker_info()
        
        # å¤åˆ¶ä¸€ä»½æ–‡ä»¶åˆ—è¡¨ï¼Œä»¥å…å½±å“å…¶ä»–åœ°æ–¹
        files = self.file_paths.copy()

        # --- A. å¤šè¿›ç¨‹ DataLoader åˆ†é…é€»è¾‘ ---
        if worker_info is not None:
            # å°†æ–‡ä»¶åˆ—è¡¨å°½å¯èƒ½å‡åŒ€åœ°åˆ†ç»™å„ä¸ª Worker
            per_worker = int(math.ceil(len(files) / float(worker_info.num_workers)))
            worker_id = worker_info.id
            iter_start = worker_id * per_worker
            iter_end = min(iter_start + per_worker, len(files))
            
            # å½“å‰ Worker åªè´Ÿè´£å¤„ç†è¿™ä¸€éƒ¨åˆ†æ–‡ä»¶
            files = files[iter_start:iter_end]

        # --- B. æ‰“ä¹±æ–‡ä»¶é¡ºåº (å®ç°å…¨å±€ Shuffle çš„æ•ˆæœ) ---
        if self.shuffle:
            random.shuffle(files)

        # --- C. é€ä¸ªæ–‡ä»¶è¯»å–å¹¶ Yield æ•°æ® ---
        for file_path in files:
            try:
                # 1. åŠ è½½ä¸€ä¸ªå°æ–‡ä»¶
                chunk_data = torch.load(file_path, weights_only = False)
                
                # 2. (å¯é€‰) æ‰“ä¹±è¿™æ‰¹æ•°æ®çš„å†…éƒ¨é¡ºåº
                if self.shuffle:
                    random.shuffle(chunk_data)
                
                # 3. é€ä¸ªå¤„ç†å¹¶â€œåâ€å‡ºæ•°æ®
                for data in chunk_data:
                    # ========================================================
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ•°æ®ç±»å‹è¿˜åŸ (De-compression) ğŸ”¥ğŸ”¥ğŸ”¥
                    # ========================================================
                    
                    # 1. é‚»å±…ç´¢å¼• (Edge Index): int32 -> int64
                    # PyTorch Geometric çš„ Message Passing å¿…é¡»ç”¨ int64 (LongTensor)
                    if hasattr(data, 'edge_index') and data.edge_index is not None:
                        if data.edge_index.dtype == torch.int32:
                            data.edge_index = data.edge_index.to(torch.long)

                    # 2. åŸå­åºæ•° (Z): int8 -> int64
                    # Embedding å±‚æŸ¥è¡¨å¿…é¡»ç”¨ int64
                    if hasattr(data, 'z') and data.z is not None:
                        if data.z.dtype == torch.int8:
                            data.z = data.z.to(torch.long)

                    # 3. å‘¨æœŸæ€§ä½ç§» (Shifts): int8 -> float32
                    # ä¹‹å‰ä¸ºäº†çœç©ºé—´å­˜æˆäº† int8 (åä¸º shifts_int)ï¼Œç°åœ¨è¦è½¬å› float32 
                    # å¹¶é‡å‘½åä¸º shiftsï¼Œä»¥ä¾¿å’Œ cell (float) è¿›è¡ŒçŸ©é˜µä¹˜æ³•
                    if hasattr(data, 'shifts_int'):
                        data.shifts = data.shifts_int.to(torch.float32)
                        # åˆ é™¤æ—§å±æ€§ä»¥èŠ‚çœå†…å­˜
                        del data.shifts_int
                    elif hasattr(data, 'shifts') and data.shifts.dtype == torch.int8:
                        # å¦‚æœåå­—æ²¡æ”¹ï¼Œç›´æ¥è½¬ç±»å‹
                        data.shifts = data.shifts.to(torch.float32)

                    # 4. è¾¹ç±»å‹ (Edge Type): int8 -> int64
                    if hasattr(data, 'edge_type') and data.edge_type is not None:
                        if data.edge_type.dtype == torch.int8:
                            data.edge_type = data.edge_type.to(torch.long)

                    # 5. ç¡®ä¿åæ ‡å’ŒåŠ›æ˜¯ float32 (é˜²æ­¢æ„å¤–å­˜æˆ double)
                    if data.pos.dtype == torch.float64:
                        data.pos = data.pos.to(torch.float32)
                    if hasattr(data, 'force') and data.force is not None:
                        if data.force.dtype == torch.float64:
                            data.force = data.force.to(torch.float32)
                    if hasattr(data, 'cell') and data.cell is not None:
                        if data.cell.dtype == torch.float64:
                            data.cell = data.cell.to(torch.float32)

                    # yield å‡ºå»çš„æ˜¯å®Œç¾çš„ã€ç¬¦åˆæ¨¡å‹è¦æ±‚çš„ Data å¯¹è±¡
                    yield data
                    
            except Exception as e:
                print(f"âš ï¸ Error loading {file_path}: {e}")
                continue
