import torch
import numpy as np
import json
import os
import glob
from torch_geometric.loader import DataLoader

# --- å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å— ---
# è¯·ç¡®ä¿è¿™äº›æ–‡ä»¶éƒ½åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œæˆ–è€…åœ¨ PYTHONPATH ä¸­
from Dataset import ShardedPyGDataset
from Model import HTGPModel
from Utils import HTGPConfig
from Potentialtrainer import PotentialTrainer # æ³¨æ„æ–‡ä»¶åå¤§å°å†™åŒ¹é…

# ==========================================
# 1. é…ç½®å‚æ•°ä¸è®¾å¤‡
# ==========================================
DATA_DIR = "/var/lib/kubelet/MUYU_data"  # æ•°æ®é›†è·¯å¾„
LOG_DIR = "Checkpoints"                  # æ—¥å¿—ä¿å­˜è·¯å¾„
BATCH_SIZE = 16
NUM_WORKERS = 4                          # è¯»å–è¿›ç¨‹æ•° (å»ºè®® 4-8)
LR = 1e-3
EPOCHS = 100

os.makedirs(LOG_DIR, exist_ok=True)

# æ£€æŸ¥æ˜¾å¡

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
os.environ["CUDA_VISIBLE_DEVICES"] = "0" 
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {DEVICE}")

# ==========================================
# 2. è‡ªåŠ¨è®¡ç®—è¿›åº¦æ¡é•¿åº¦ (å…³é”®æ­¥éª¤)
# ==========================================
print("\n[1/5] Calculating dataset size...")

meta_path = os.path.join(DATA_DIR, "meta_data.pt")
CHUNK_SIZE = 5120 # é»˜è®¤å€¼ï¼Œé˜²æ­¢è¯»å–å¤±è´¥
if os.path.exists(meta_path):
    try:
        meta_data = torch.load(meta_path, weights_only=False)
        if 'config' in meta_data and 'chunk_size' in meta_data['config']:
            CHUNK_SIZE = meta_data['config']['chunk_size']
            print(f"â„¹ï¸  Chunk Size identified: {CHUNK_SIZE}")
    except Exception as e:
        print(f"âš ï¸  Error reading chunk size: {e}")

# ç»Ÿè®¡æ–‡ä»¶æ•°é‡
train_files = glob.glob(os.path.join(DATA_DIR, "train_*.pt"))
test_files = glob.glob(os.path.join(DATA_DIR, "test_*.pt"))
train_files_count = len(train_files)
test_files_count = len(test_files)

if train_files_count == 0:
    raise FileNotFoundError(f"âŒ åœ¨ {DATA_DIR} æœªæ‰¾åˆ° train_*.pt æ–‡ä»¶ï¼")

# è®¡ç®—æ€»æ­¥æ•° (ç”¨äº tqdm è¿›åº¦æ¡)
# å…¬å¼: æ€»æ•°æ®é‡ / BatchSize
# æ€»æ•°æ®é‡ = æ–‡ä»¶æ•° * æ¯ä¸ªæ–‡ä»¶çš„å®¹é‡(ChunkSize)
TRAIN_STEPS = (train_files_count * CHUNK_SIZE) // BATCH_SIZE
CHUNK_SIZE_TEST = 5120  # é»˜è®¤å€¼
TEST_STEPS = (test_files_count * CHUNK_SIZE_TEST) // BATCH_SIZE

# é˜²æ­¢ Test é›†å¤ªå°å¯¼è‡´ step ä¸º 0
if TEST_STEPS == 0 and test_files_count > 0: TEST_STEPS = 1

print(f"ğŸ“Š è®­ç»ƒé›†: {train_files_count} files | Est. Steps: {TRAIN_STEPS}")
print(f"ğŸ“Š æµ‹è¯•é›†: {test_files_count} files | Est. Steps: {TEST_STEPS}")

# ==========================================
# 3. å®ä¾‹åŒ– Dataset å’Œ DataLoader
# ==========================================
print("\n[2/5] Initializing DataLoaders...")

train_dataset = ShardedPyGDataset(DATA_DIR, prefix="train", shuffle=True)
test_dataset = ShardedPyGDataset(DATA_DIR, prefix="test", shuffle=False)

# æ³¨æ„ï¼šæµå¼æ•°æ®é›†å¿…é¡» shuffle=False
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,          # âŒ å¿…é¡»ä¸º False
    num_workers=NUM_WORKERS,
    pin_memory=True,        # âœ… åŠ é€Ÿ
    prefetch_factor=2,      # âœ… é¢„å–
    persistent_workers=True # âœ… ä¿æŒ Worker æ´»è·ƒ
)

test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)

# ==========================================
# 4. æ¨¡å‹åˆå§‹åŒ–
# ==========================================
print("\n[3/5] Building Model...")

config = HTGPConfig(
    num_atom_types=60,      # æ ¹æ®æ•°æ®é›†è°ƒæ•´
    hidden_dim=128,
    num_layers=2,
    cutoff=6.0,
    use_L2=True,
    use_gating=True,
    use_long_range=False
)

model = HTGPModel(config).to(DEVICE)
print(f"ğŸ§  Model Parameters: {sum(p.numel() for p in model.parameters())}")

# ==========================================
# 5. æ³¨å…¥ E0 (åŸå­å¹³å‡èƒ½é‡)
# ==========================================
print("\n[4/5] Loading Atomic References (E0)...")

if os.path.exists(meta_path):
    meta_data = torch.load(meta_path, weights_only=False)
    # è·å– e0_dict
    e0_dict = meta_data.get('e0_dict', None)
    
    if e0_dict:
        print(f"âœ… E0 Dict Loaded.")
        with torch.no_grad():
            count = 0
            for z, e in e0_dict.items():
                z_idx = int(z)
                if z_idx < model.atomic_ref.weight.size(0):
                    model.atomic_ref.weight[z_idx] = torch.tensor(e, dtype=model.atomic_ref.weight.dtype)
                    count += 1
            print(f"ğŸ”’ Injected and froze E0 for {count} elements.")
        
        # å†»ç»“å‚æ•°
        model.atomic_ref.weight.requires_grad = False
    else:
        raise ValueError("âŒ meta_data.pt found but 'e0_dict' is missing!")
else:
    raise FileNotFoundError("âŒ meta_data.pt not found! Please run 'calc_e0.py' first.")

# ==========================================
# 6. è®­ç»ƒå‡†å¤‡
# ==========================================
trainer = PotentialTrainer(model, lr=LR, device=DEVICE, checkpoint_dir=LOG_DIR)

# å†å²è®°å½•
history = {
    'epoch': [],
    'train_loss': [], 'val_loss': [],
    'train_mae_e': [], 'val_mae_e': [],
    'train_mae_f': [], 'val_mae_f': [],
    'train_mae_s': [], 'val_mae_s': []
}

def save_history():
    with open(f"{LOG_DIR}/history.json", 'w') as f:
        json.dump(history, f, indent=4)

print("\n" + "="*105)
print(f"{'Epoch':^6} | {'TrainLoss':^10} | {'ValLoss':^10} | "
      f"{'Tr E (meV)':^10} | {'Tr F (meV)':^10} | {'Tr S (GPa)':^10} | "
      f"{'Val E':^10} | {'Val F':^10} | {'Val S':^10}")
print("="*105)

# ==========================================
# 7. ğŸ”¥ è®­ç»ƒå¾ªç¯
# ==========================================
print("\n[5/5] Starting Training Loop...")

# Optional: Run a baseline validation first (Epoch 0)
# print("Running baseline validation...")
# base_metrics = trainer.validate(test_loader, total_steps=TEST_STEPS)
# print(f"Baseline Val Loss: {base_metrics['total']:.4f}")

best_val_loss = float('inf')

for epoch in range(1, EPOCHS + 1):
    # 1. è®­ç»ƒ (ä¼ å…¥ total_steps æ˜¾ç¤ºè¿›åº¦æ¡)
    train_metrics = trainer.train_epoch(train_loader, total_steps=TRAIN_STEPS)
    
    # 2. éªŒè¯
    val_metrics = trainer.validate(test_loader, total_steps=TEST_STEPS)
    
    # 3. è®°å½•æ—¥å¿—
    history['epoch'].append(epoch)
    history['train_loss'].append(train_metrics['total'])
    history['val_loss'].append(val_metrics['total'])
    
    # å•ä½è½¬æ¢: eV -> meV
    history['train_mae_e'].append(train_metrics['mae_e'] * 1000)
    history['val_mae_e'].append(val_metrics['mae_e'] * 1000)
    history['train_mae_f'].append(train_metrics['mae_f'] * 1000)
    history['val_mae_f'].append(val_metrics['mae_f'] * 1000)
    
    history['train_mae_s'].append(train_metrics['mae_s'])
    history['val_mae_s'].append(val_metrics['mae_s'])
    
    save_history()

    # 4. æ‰“å°ä¸€è¡Œæ—¥å¿—
    log_str = (
        f"{epoch:^6} | "
        f"{train_metrics['total']:^10.4f} | "
        f"{val_metrics['total']:^10.4f} | "
        f"{train_metrics['mae_e']*1000:^10.2f} | "
        f"{train_metrics['mae_f']*1000:^10.2f} | "
        f"{train_metrics['mae_s']:^10.3f} | "
        f"{val_metrics['mae_e']*1000:^10.2f} | "
        f"{val_metrics['mae_f']*1000:^10.2f} | "
        f"{val_metrics['mae_s']:^10.3f}"
    )
    print(log_str)

    # 5. ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_metrics['total'] < best_val_loss:
        best_val_loss = val_metrics['total']
        trainer.save('best_model.pt')

print("\nğŸ‰ Training Finished!")
