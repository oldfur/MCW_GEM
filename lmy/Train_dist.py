import os
import json
import torch
import torch.distributed as dist
import numpy as np
from torch.nn.parallel import DistributedDataParallel as DDP
from torch_geometric.loader import DataLoader

# --- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— (æ ¹æ®ä½ çš„é¡¹ç›®ç»“æ„) ---
from src.data import ChunkedSmartDataset_h5, BinPackingSampler
from src.models import HTGPModel
from src.utils import HTGPConfig
from src.engine import PotentialTrainer 

# ==========================================
# 0. å…¨å±€ç¯å¢ƒè®¾ç½® (Environment Setup)
# ==========================================
# è§£å†³å¤šè¿›ç¨‹æ–‡ä»¶æ‰“å¼€æ•°é™åˆ¶é—®é¢˜
torch.multiprocessing.set_sharing_strategy('file_system')

# è®¾ç½®é»˜è®¤ç²¾åº¦
torch.set_default_dtype(torch.float32)

# ğŸš€ å¼€å¯ TF32 (NVIDIA Ampere/Hopper æ¶æ„åŠ é€Ÿç¥å™¨)
torch.backends.cuda.matmul.allow_tf32 = True 
torch.backends.cudnn.allow_tf32 = True

# ==========================================
# 1. è®­ç»ƒé…ç½® (Configuration)
# ==========================================
class Config:
    # è·¯å¾„é…ç½®
    DATA_DIR = "../dataset_h5"      # æ•°æ®æ ¹ç›®å½•
    TRAIN_META = "train_metadata.pt"         # è®­ç»ƒé›†å…ƒæ•°æ®
    TEST_META = "test_metadata.pt"           # æµ‹è¯•é›†å…ƒæ•°æ®
    E0_PATH = "../dataset_h5/meta_data.pt" # åŸå­èƒ½é‡å‚è€ƒå€¼
    LOG_DIR = "../lmy_Checkpoints"                  # æ¨¡å‹ä¿å­˜è·¯å¾„

    # è®­ç»ƒè¶…å‚
    # ğŸ”¥ æ³¨æ„: è¿™é‡Œçš„ BATCH_SIZE æŒ‡çš„æ˜¯ "æ¯ä¸ª Batch çš„æœ€å¤§åŸå­æ•° (Cost)"
    MAX_COST_PER_BATCH = 2000  # é’ˆå¯¹ H100/A100 ä¼˜åŒ–
    LR = 1e-3
    EPOCHS = 45
    
    # ç³»ç»Ÿé…ç½®
    NUM_WORKERS = 8            # DataLoader è¿›ç¨‹æ•°
    PREFETCH_FACTOR = 2        # é¢„å–å› å­

    # æ¨¡å‹é…ç½® (HTGP)
    MODEL_PARAMS = dict(
        num_atom_types=100, 
        hidden_dim=128, 
        num_layers=2, 
        cutoff=6.0, 
        num_rbf=10,
        use_L0=True, 
        use_L1=True,
        use_L2=True, 
        use_gating=True, 
        use_long_range=False
    )

# ==========================================
# 2. è¾…åŠ©å‡½æ•° (Utils)
# ==========================================
def init_distributed_mode():
    """åˆå§‹åŒ– DDP åˆ†å¸ƒå¼ç¯å¢ƒ"""
    if "RANK" in os.environ and "WORLD_SIZE" in os.environ:
        rank = int(os.environ["RANK"])
        world_size = int(os.environ["WORLD_SIZE"])
        local_rank = int(os.environ["LOCAL_RANK"])
        
        torch.cuda.set_device(local_rank)
        dist.init_process_group(backend="nccl", init_method="env://", world_size=world_size, rank=rank)
        dist.barrier()
        return local_rank, rank, world_size
    else:
        print("âš ï¸ Warning: Running in Single GPU Mode")
        return 0, 0, 1

def log_info(msg, rank):
    """ä»…åœ¨ä¸»è¿›ç¨‹æ‰“å°æ—¥å¿—"""
    if rank == 0:
        print(msg)

def get_dataloader(data_dir, meta_file, rank, world_size, is_train=True):
    """æ„å»º Dataset, Sampler å’Œ DataLoader"""
    full_path = os.path.join(data_dir, meta_file)
    if not os.path.exists(full_path):
        if is_train:
            raise FileNotFoundError(f"âŒ è‡´å‘½é”™è¯¯: æ²¡æ‰¾åˆ° {meta_file}ï¼Œè¯·å…ˆè¿è¡Œ preprocess.pyï¼")
        else:
            log_info(f"âš ï¸ Warning: {meta_file} not found, skipping...", rank)
            return None, None

    # 1. Dataset
    dataset = ChunkedSmartDataset_h5(
        data_dir, 
        metadata_file=meta_file, 
        rank=rank,
        world_size=world_size
    )

    # 2. Sampler (è®­ç»ƒç”¨ Shuffle, æµ‹è¯•ä¸ç”¨)
    sampler = BinPackingSampler(
        dataset.metadata,
        max_cost=Config.MAX_COST_PER_BATCH,
        edge_weight="auto",
        shuffle=is_train,
        world_size=world_size,
        rank=rank
    )

    # 3. Loader
    loader = DataLoader(
        dataset,
        batch_sampler=sampler, # å…³é”®ï¼šä½¿ç”¨ batch_sampler å¤„ç†åŠ¨æ€ Batch
        num_workers=Config.NUM_WORKERS,
        pin_memory=True,
        prefetch_factor=Config.PREFETCH_FACTOR,
    )
    
    return loader, sampler

def build_model(device, rank, avg_neighborhood, **karwgs):
    """æ„å»ºæ¨¡å‹å¹¶åŠ è½½ E0"""
    
    # åˆå§‹åŒ–é…ç½®å’Œæ¨¡å‹

    if "restart" not in karwgs:
        model_config = HTGPConfig(**Config.MODEL_PARAMS)
        model_config.avg_neighborhood = avg_neighborhood
        model = HTGPModel(model_config).to(device)
    else:
        model_config = karwgs["model_config"]
        model_config.avg_neighborhood = avg_neighborhood
        model = HTGPModel(model_config).to(device)
        state_dict = karwgs["state_dict"]
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v 
            else:
                new_state_dict[k] = v
        print()
    
    # æ‰“å°å‚æ•°é‡
    if rank == 0:
        param_count = sum(p.numel() for p in model.parameters())
        log_info(f"ğŸ§  Model Parameters: {param_count:,}", rank)


    # æ³¨å…¥ E0 (åŸå­å‚è€ƒèƒ½é‡)
    if "restart" not in karwgs:
        if os.path.exists(Config.E0_PATH):
            # map_location='cpu' é˜²æ­¢å ç”¨æ˜¾å­˜
            meta_data = torch.load(Config.E0_PATH, map_location='cpu', weights_only=False)
            e0_dict = meta_data.get('e0_dict', None)
            
            model.load_external_e0(e0_dict)
            model.atomic_ref.weight.requires_grad = False # å†»ç»“ E0
            if rank == 0:
                log_info(f"Adding E0 from {Config.E0_PATH}...", rank)

        else:
            # å¦‚æœæ²¡æœ‰ E0 æ–‡ä»¶ï¼Œç¡®ä¿ç±»å‹æ­£ç¡®
            model.atomic_ref.weight = model.atomic_ref.weight.float()
            log_info("âš ï¸ meta_e0_data.pt not found, skipping E0 injection.", rank)

    # DDP åŒ…è£…
    if dist.is_initialized():
        model = DDP(model, device_ids=[device.index], output_device=device.index, find_unused_parameters=True)
    
    return model

# ==========================================
# 3. ä¸»ç¨‹åº (Main)
# ==========================================
def main():
    # --- A. åˆå§‹åŒ–ç¯å¢ƒ ---
    local_rank, rank, world_size = init_distributed_mode()
    device = torch.device(f"cuda:{local_rank}")
    
    if rank == 0:
        os.makedirs(Config.LOG_DIR, exist_ok=True)
        log_info(f"\nğŸš€ [Start] World Size: {world_size} | Device: {device}", rank)
        log_info("="*60, rank)

    # --- B. å‡†å¤‡æ•°æ® ---
    log_info("\n[1/4] Initializing DataLoaders...", rank)
    
    # è®­ç»ƒé›†
    train_loader, train_sampler = get_dataloader(
        Config.DATA_DIR, Config.TRAIN_META, rank, world_size, is_train=True
    )
    
    # æµ‹è¯•é›† 
    test_loader, test_sampler = get_dataloader(
        Config.DATA_DIR, Config.TEST_META, rank, world_size, is_train=False
    )
    # è¿™é‡Œçš„è§£åŒ…é€»è¾‘ç¨å¾®æ”¹ä¸€ä¸‹ï¼Œé˜²æ­¢ test_result ä¸º None æŠ¥é”™
    # test_loader = test_result[0] if test_result else None

    # --- C. æ„å»ºæ¨¡å‹ ---
    log_info("\n[2/4] Building Model...", rank)\
    
    restart = True  # æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    avg_neighborhood = 1 / train_sampler.edge_weight
    if not restart:
        model = build_model(device, rank, avg_neighborhood)
    else:
        checkpoint_path = "../lmy_Checkpoints/model_epoch_5.pt"
        checkpoint_weights = torch.load(checkpoint_path, map_location=device, weights_only=False)
        saved_config = checkpoint_weights['model_config']

        model = build_model(device, rank, avg_neighborhood, restart=restart, model_config=saved_config, state_dict=checkpoint_weights)

    # --- D. åˆå§‹åŒ– Trainer ---
    log_info("\n[3/4] Initializing Trainer...", rank)
    
    # ä¼°ç®—æ€»æ­¥æ•° (å› ä¸ºæ˜¯åŠ¨æ€ Batchï¼Œæ­¥æ•°ä¸æ˜¯å›ºå®šçš„ len/bsï¼Œéœ€è¦ä» sampler è·å–)
    train_total_steps = train_sampler.precompute_total_steps(Config.EPOCHS)
    log_info(f"ğŸ“Š Estimated total steps for training: {train_total_steps}", rank)

    # ğŸ”¥ ä¿®æ”¹ 2: å¿…é¡»åŠ  if åˆ¤æ–­ï¼Œå¦åˆ™ test_sampler ä¸º None æ—¶ä¼šæŠ¥é”™
    if test_sampler is not None:
        test_total_steps = test_sampler.precompute_total_steps(Config.EPOCHS)
        log_info(f"ğŸ“Š Estimated total steps for testing: {test_total_steps}", rank)

    if not restart:
        trainer = PotentialTrainer(
        model, 
        total_steps=train_total_steps,
        max_lr=Config.LR, 
        device=device, 
        checkpoint_dir=Config.LOG_DIR)
    else:
        trainer = PotentialTrainer(
        model, 
        total_steps=train_total_steps,
        max_lr=Config.LR, 
        device=device, 
        checkpoint_dir=Config.LOG_DIR)

    # --- E. è®­ç»ƒå¾ªç¯ ---
    log_info("\n[4/4] Starting Loop...", rank)
    log_info("="*60, rank)


    for epoch in range(1, Config.EPOCHS + 1):
        # é‡è¦ï¼šæ¯ä¸ª Epoch è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ Shuffle æ•ˆæœ
        train_sampler.set_epoch(epoch)
        
        # 1. Train
        train_metrics = trainer.train_epoch(train_loader, epoch_idx=epoch)
        
        # 2. Validate
        if test_loader:
            val_metrics = trainer.validate(test_loader, epoch_idx=epoch)
        else:
            val_metrics = {'total_loss': 0.0, 'mae_f': 0.0}

        # 3. Log & Save (ä»… Rank 0)
        if rank == 0:
            log_msg = (
                f"Ep {epoch:03d} | "
                f"T_Loss: {train_metrics['total_loss']:.4f} | "
                f"V_Loss: {val_metrics['total_loss']:.4f} | "
                f"MAE_F: {train_metrics['mae_f']*1000:.1f}/{val_metrics['mae_f']*1000:.1f} meV/A"
            )
            print(log_msg)
            trainer.save(f'model_epoch_{epoch}.pt')

        # 4. åŒæ­¥ï¼šç¡®ä¿æ‰€æœ‰å¡éƒ½è·‘å®Œäº†è¿™ä¸ª Epoch
        if dist.is_initialized():
            dist.barrier()

    log_info("\nâœ… Training Finished!", rank)
    
    # --- F. æ¸…ç† ---
    if dist.is_initialized():
        dist.destroy_process_group()

if __name__ == "__main__":
    # è®¾ç½® OMP çº¿ç¨‹æ•°ï¼Œé˜²æ­¢ CPU è¿‡è½½
    os.environ["OMP_NUM_THREADS"] = "1" 
    main()