# ==========================================
# ğŸ”¥ å¿…é¡»æ”¾åœ¨æ–‡ä»¶æœ€æœ€æœ€å¼€å¤´ï¼ğŸ”¥
# åœ¨å¯¼å…¥ä»»ä½• torch/numpy ä¹‹å‰å°±é™åˆ¶çº¿ç¨‹
# ==========================================
import os
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"
os.environ["VECLIB_MAXIMUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"

# ==========================================
# ç°åœ¨æ‰å¼€å§‹å¯¼å…¥å…¶ä»–åº“
# ==========================================
import torch
import random
import multiprocessing
import gc
import numpy as np
from tqdm import tqdm

# å‡è®¾ä½ çš„è½¬æ¢å‡½æ•°åœ¨è¿™é‡Œ (è¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹)
from extxyz_to_pyg_custom_new import extxyz_to_pyg_custom 

def worker_task(args):
    """
    Worker è¿›ç¨‹ä»»åŠ¡ï¼š
    1. è¯»å– XYZ æ–‡ä»¶
    2. è½¬æ¢ä¸º PyG å›¾æ•°æ® (è®¡ç®—è¾¹/é‚»å±…)
    3. ä¿å­˜æ•°æ®å— (.pt)
    4. è¿”å›å…ƒæ•°æ® (Metadata) ç»™ä¸»è¿›ç¨‹
    """
    # åŒé‡ä¿é™©
    torch.set_num_threads(1)
    
    worker_id, file_paths, save_dir, prefix, cutoff, chunk_size = args
    
    buffer = []
    local_metadata = [] # ğŸ”¥ é‡ç‚¹ï¼šåªå­˜ç´¢å¼•ä¿¡æ¯
    save_counter = 0
    
    try:
        for fpath in file_paths:
            if os.path.getsize(fpath) == 0: continue

            # 1. è¿™é‡Œè¿›è¡Œæœ€è€—æ—¶çš„å›¾è®¡ç®— (è®¡ç®—è¾¹ã€é‚»å±…)
            # extxyz_to_pyg_custom å†…éƒ¨åº”è°ƒç”¨ neighbor_list æˆ– radius_graph
            try:
                data_list = extxyz_to_pyg_custom(fpath, cutoff=cutoff)
            except Exception as e:
                print(f"Skipping bad file {fpath}: {e}")
                continue
            
            if not data_list: continue

            for data in data_list:
                buffer.append(data)
                
                # ğŸ”¥ 2. è®°å½•å…ƒæ•°æ® (ä¸ºå¤šç›®æ ‡ä¼˜åŒ–åšå‡†å¤‡)
                # è®°å½•ï¼šè¿™ä¸ªå›¾åœ¨å“ªä¸ªæ–‡ä»¶çš„å“ªä¸ªä½ç½®ï¼Œæœ‰å¤šå¤§
                # è¿™ä¸ª dict éå¸¸å°ï¼Œå‡ ç™¾ä¸‡ä¸ªæ ·æœ¬ä¹Ÿå°±å‡ ç™¾ MB å†…å­˜
                local_metadata.append({
                    'file_path': f"{prefix}_w{worker_id}_p{save_counter}.pt", # æ•°æ®å­˜åœ¨å“ªä¸ªæ–‡ä»¶
                    'index_in_file': len(buffer) - 1,                         # æ–‡ä»¶é‡Œçš„ç¬¬å‡ ä¸ª
                    'num_atoms': data.num_nodes,                              # æ˜¾å­˜ç“¶é¢ˆ
                    'num_edges': data.edge_index.size(1)                      # è®¡ç®—ç“¶é¢ˆ
                })

                # 3. å­˜ç›˜é€»è¾‘
                if len(buffer) >= chunk_size:
                    save_name = f"{prefix}_w{worker_id}_p{save_counter}.pt"
                    full_path = os.path.join(save_dir, save_name)
                    
                    # ä½¿ç”¨ torch.save ä¿å­˜ buffer
                    torch.save(buffer, full_path)
                    
                    buffer = []
                    save_counter += 1
                    gc.collect() # æ˜¾å¼ GC é˜²æ­¢å†…å­˜æ³„æ¼

        # å¤„ç†å‰©ä½™æ•°æ® (Last Chunk)
        if buffer:
            save_name = f"{prefix}_w{worker_id}_p{save_counter}.pt"
            torch.save(buffer, os.path.join(save_dir, save_name))
            gc.collect()
        
        return local_metadata # è¿”å›å…ƒæ•°æ®ç»™ä¸»è¿›ç¨‹åˆå¹¶

    except Exception as e:
        print(f"Error in worker {worker_id}: {e}")
        # å‡ºé”™æ—¶å°½é‡è¿”å›å·²æ”¶é›†çš„å…ƒæ•°æ®ï¼Œé¿å…å…¨éƒ¨ä¸¢å¤±
        return local_metadata

def main():
    # 1. è®¾ç½®å…±äº«ç­–ç•¥ (é˜²æ­¢ Too many open files é”™è¯¯)
    try:
        torch.multiprocessing.set_sharing_strategy('file_system')
    except:
        pass

    # 2. å‡†å¤‡æ–‡ä»¶è·¯å¾„
    # è¯·æ ¹æ®ä½ çš„å®é™…ç›®å½•ä¿®æ”¹è¿™é‡Œ
    file_dirs = [r"../005_all", r"../100_all", r"../outcar_selected_xyz", r"../xyz_grouped"]
    all_files = []
    unique_names = set()

    print("ğŸ” Scanning files...")
    for d in file_dirs:
        if os.path.exists(d):
            # è·å–å®Œæ•´è·¯å¾„
            files_in_dir = [os.path.join(d, f) for f in os.listdir(d) if f.endswith('.xyz')]
            all_files.extend(files_in_dir)

            # è·å–å”¯ä¸€æ ‡è¯†å (é˜²æ­¢æ•°æ®æ³„æ¼)
            for f in os.listdir(d):
                if f.endswith('.xyz'):
                    unique_names.add(f.split('.')[0])
    
    print(f"ğŸ“‚ Found {len(all_files)} files with {len(unique_names)} unique names.")

    # 3. é…ç½®å‚æ•°
    NUM_WORKERS = 120    # å»ºè®® 8-16ï¼Œå¤ªé«˜ä¼šå¡ IO
    CHUNK_SIZE = 100   # æ¯ä¸ª .pt æ–‡ä»¶å­˜å¤šå°‘ä¸ªå›¾ (è¶Šå¤§è¯»å–è¶Šå¿«ï¼Œä½†éšæœºæ€§è¶Šå·®)
    SAVE_DIR = "../processed_data"
    CUTOFF = 6.0
    TEST_RATIO = 0.05
    
    os.makedirs(SAVE_DIR, exist_ok=True)

    # 4. åˆ’åˆ†æ•°æ®é›† (æŒ‰ unique name)
    unique_names_list = sorted(list(unique_names))  # æ’åºä¿è¯å¯å¤ç°
    random.seed(42)
    random.shuffle(unique_names_list)
    
    num_test = max(1, int(len(unique_names_list) * TEST_RATIO))
    test_names_set = set(unique_names_list[:num_test])
    train_names_set = set(unique_names_list[num_test:])

    # é‡æ–°è¿‡æ»¤æ–‡ä»¶
    train_files = []
    test_files = []
    
    for f in all_files:
        # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º "MoleculeName.xyz" æˆ– "MoleculeName.config1.xyz"
        # è¿™é‡Œå–ç¬¬ä¸€ä¸ªç‚¹å‰çš„éƒ¨åˆ†ä½œä¸ºå”¯ä¸€æ ‡è¯†
        fname = f.split(os.sep)[-1].split('.')[0] 

        if fname in train_names_set:
            train_files.append(f)
        elif fname in test_names_set:
            test_files.append(f)

    # ç®€å•æ‰“ä¹±æ–‡ä»¶é¡ºåº (é¢„Shuffle)
    random.shuffle(train_files)
    random.shuffle(test_files)
    print(f"ğŸš‚ Training files: {len(train_files)}, Testing files: {len(test_files)}")


    # ==========================================
    # å¤„ç†æµ‹è¯•é›† (Test)
    # ==========================================
    if test_files:
        print(f"\nğŸš€ Processing Test Set ({len(test_files)} files)...")
        
        real_workers = min(NUM_WORKERS, len(test_files))
        if real_workers > 0:
            file_chunks = np.array_split(test_files, real_workers)
            tasks = []
            for i in range(real_workers):
                tasks.append((i, file_chunks[i].tolist(), SAVE_DIR, "test", CUTOFF, CHUNK_SIZE))
            
            all_test_metadata = []
            with multiprocessing.Pool(real_workers) as pool:
                for meta in tqdm(pool.imap_unordered(worker_task, tasks), total=real_workers):
                    all_test_metadata.extend(meta)

            # ğŸ”¥ ä¿å­˜æµ‹è¯•é›†æ€»ç´¢å¼•æ–‡ä»¶
            torch.save(all_test_metadata, os.path.join(SAVE_DIR, "test_metadata.pt"))
            print(f"âœ… Test Done! Metadata saved: {len(all_test_metadata)} samples.")


    # ==========================================
    # å¤„ç†è®­ç»ƒé›† (Train)
    # ==========================================
    if train_files:
        print(f"\nğŸš€ Processing Train Set ({len(train_files)} files)...")
        
        # åŠ¨æ€åˆ†é… Worker
        real_workers = min(NUM_WORKERS, len(train_files))
        file_chunks = np.array_split(train_files, real_workers)
        
        tasks = []
        for i in range(real_workers):
            # args: worker_id, file_paths, save_dir, prefix, cutoff, chunk_size
            tasks.append((i, file_chunks[i].tolist(), SAVE_DIR, "train", CUTOFF, CHUNK_SIZE))
        
        all_train_metadata = []
        
        with multiprocessing.Pool(real_workers) as pool:
            # imap ä¿è¯æœ‰åºè¿”å›ç»“æœï¼Œæˆ–è€…ç”¨ imap_unordered æ›´å¿«ä½†ä¹±åº
            # è¿™é‡Œç”¨ tqdm åŒ…è£…è¿›åº¦æ¡
            for meta in tqdm(pool.imap_unordered(worker_task, tasks), total=real_workers):
                all_train_metadata.extend(meta)

        # ğŸ”¥ ä¿å­˜è®­ç»ƒé›†æ€»ç´¢å¼•æ–‡ä»¶
        torch.save(all_train_metadata, os.path.join(SAVE_DIR, "train_metadata.pt"))
        print(f"âœ… Train Done! Metadata saved: {len(all_train_metadata)} samples.")

    print("\nğŸ‰ All processing finished successfully.")

if __name__ == "__main__":
    multiprocessing.freeze_support()
    main()